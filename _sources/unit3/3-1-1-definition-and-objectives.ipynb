{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99aa539",
   "metadata": {},
   "source": [
    "# 1. Overview and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce1c03",
   "metadata": {},
   "source": [
    "## a. Definition and objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda2b3e",
   "metadata": {},
   "source": [
    "### 1. What is the purpose of indexing data ?\n",
    "\n",
    "The number of documents available in a collection can make the process of retrieving information difficult. To access a particular document without the use of an index, there is no other choice than checking every document one by one. This is called a *sequential search*. As you can imagine, this is not a very efficient method: the more documents there are, the longer the search. To overcome this problem, is is possible to create indexes on various fields of a document. A field corresponds to part of a document (its title, its publication date, its text, *etc.*). Conceptually, an index associates the value of a field with the location of the document in the system. For example, in a library, it is much more efficient to consult the catalog to know where a particular book is located rather than scannning through all the books until the relevant one is found.\n",
    "\n",
    "Indexing data is a crucial part of archival work as it is the basis for the public use of historical sources. \n",
    "An example of the indexing process in the Universal Decimal Classification (UDC). Created at the end of the 19th century, it is a hierarchical system trying to classify information in 9 main classes representing human knowledge (Social sciences, mathematics, philosophy, *etc.*). These classes are divided into 10 subparts that can themselves be further divided. The UDC also integrates special characters allowing for more precise queries. For example, the query **17:7** concerns documents about Ethics (category 17) in relation to Arts (category 7).\n",
    "This system was used in the creation of the Mundaneum in Belgium, a building which objective was to collect and archive knowledge. It contains about 12 millions cards, classified according to the UDC. It is said to be the first search engine.\n",
    "\n",
    "![Mundaneum](img/mundaneum.jpg)\n",
    "CC-BY Mark Wathieu\n",
    "\n",
    "Using digital systems to archive documents brings a change of paradigm, both for archivists and end-users. The quantity of available information does not cease to grow. On the one hand it is extremely useful as it allows researchers to *easily* work on massive collections of documents. On the other hand it brings up new difficulties, challenges and pitfalls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652da34",
   "metadata": {},
   "source": [
    "## b. Tools and methodology\n",
    "\n",
    "When indexing a large collection of documents, it is necessary to think about what should effectively be indexed. You have to remember that indexing is a trade-off between disk space/processing power VS speed of search. Thus, indexing too much data can eventually hurt the search capabilities of a system if it is not ready to handle many indexes.\n",
    "\n",
    "Another thing to think about is the end-users' needs. It is important to evaluate these needs beforehand so as to not waste processing power on indexes that will never be used. Let's take as an example the case of the NewsEye project. One of its use case is to be able to highlight individual words in newspapers pages. The pipeline used in this project generates for every page of newspaper a XML file containing information on the position of every word in the page. One would think it is a good idea to index individual words with their position as to ease their retrieval. However, because there are lots of pages and because each page can contain up to 10,000 words, the number of words indexed would easily reach hundreds of millions, even billions. This is not desirable as it would increase the size of an index dramatically, thus slowing the entire system. A solution for this problem is to not index individual words but rather parse the XML file and get the words and their positions when needed (after a particular user query).\n",
    "\n",
    "During this course, we will learn how to use Solr, a software to index and retrieve data. Based on Apache Lucene, this software can be used to ingest large quantity of data and make them available for search through an API. The principles we will study in this course will still apply to other indexing softwares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15856da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
