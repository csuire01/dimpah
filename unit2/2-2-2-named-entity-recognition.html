
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Named Entity Recognition (NER) &#8212; DiMPAH - Digital Historical Research on European Historical Newspapers with the NewsEye Platform</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DiMPAH - Digital Historical Research on European Historical Newspapers with the NewsEye Platform</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Digital Historical Research on European Historical Newspapers with the NewsEye Platform
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction to historical newspaper analysis and digitisation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../unit1/1-intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Information extraction and document understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2-intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Document retrieval and information seeking
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../unit3/3-intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit3/3-1-text-indexing.html">
   Understanding text indexing process
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-1-1-definition-and-objectives.html">
     Definition and objectives
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-1-2-indexing-metadata.html">
     Indexing Metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-1-3-indexing-indexing-text-content.html">
     Indexing text content
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit3/3-2-text-search.html">
   Text Search Algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-2-1-ranking-problem.html">
     1. Introduction to Ranking Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-2-2-searching-with-solr.html">
     2. Searching with Solr
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-2-3-result-representations.html">
     Result representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unit3/3-3-advanced-search.html">
   Advanced Search in Historical documents
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-3-1-demonstration-of-blackboxes.html">
     Demonstration of blackboxes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-3-2-search-and-exploration.html">
     Advanced Search and Exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../unit3/3-3-3-critical-thinking.html">
     Critical Thinking on NewsEye Examples
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/unit2/2-2-2-named-entity-recognition.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/csuire01/dimpah"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/csuire01/dimpah/issues/new?title=Issue%20on%20page%20%2Funit2/2-2-2-named-entity-recognition.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/csuire01/dimpah/main?urlpath=tree/dimpah_io4/unit2/2-2-2-named-entity-recognition.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-what-are-named-entities">
   (a) What are named entities?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#b-why-are-named-entities-important-case-studies">
   (b) Why are named entities important? (case studies)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classifying-content-for-news-providers">
     Classifying content for news providers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automating-customer-support">
     Automating customer support
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exploring-historical-documents">
     Exploring historical documents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-valuable-information-from-medical-documents">
     Extracting valuable information from medical documents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aiding-risk-assessment-for-financial-institutions">
     Aiding risk assessment for financial institutions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#easing-the-research-process">
     Easing the research process
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#c-named-entity-recognition-with-nltk-spacy">
   (c) Named Entity Recognition with NLTK &amp; spaCy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#i-ner-with-nltk">
   i. NER with NLTK
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ii-ner-with-spacy">
   ii. NER with spaCy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#iii-how-to-build-or-train-a-ner-model">
   iii. How to build or train a NER model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     Dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-format-iob-tagging-scheme">
     Data format (IOB tagging scheme)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-choose-the-train-dev-and-test-sets">
     How to choose the train, dev and test sets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-principles-ml-training-data-etc">
   General principles (ML, training data, etc)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-state-of-the-art-examples-list-of-sota-papers">
   (d) State-of-the-art examples (list of SotA papers)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#e-entity-linking">
   (e) Entity linking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-use-case-mapping-locations-on-a-map">
   (d) Use-case (mapping locations on a map)
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="named-entity-recognition-ner">
<h1>1. Named Entity Recognition (NER)<a class="headerlink" href="#named-entity-recognition-ner" title="Permalink to this headline">¶</a></h1>
<p>Named entity recognition (NER) task aims at identifying real-world entities, such as names of people, organizations, and locations within historical documents. The term of <em>named entity (NE)</em>, widely used in Information Extraction (IE) or other Natural Language Processing (NLP) applications, was born in the Message Understanding Conferences (MUC) which influenced the IE research between 1988 and 1996. Since 1999, the yearly conference on
Natural Language Learning (CoNLL) covers a large framework of topics about NLP, mostly through machine learning approaches.</p>
<div class="section" id="a-what-are-named-entities">
<h2>(a) What are named entities?<a class="headerlink" href="#a-what-are-named-entities" title="Permalink to this headline">¶</a></h2>
<p>Named entities are generally proper nouns that refer to specific entities that can be a person, organization, location, date, etc. If we consider this sentence as an example: <em>Mount Everest is the tallest mountain above sea level</em>, NER should detect <em>Mount Everest</em> as a named entity of type location as it refers to a specific entity.</p>
<p>Some other examples of named entities are listed in the following table:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Named Entity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ORGANIZATION</p></td>
<td><p>United Nations Organization, UNICEF, Microsoft</p></td>
</tr>
<tr class="row-odd"><td><p>PERSON</p></td>
<td><p>Novak Djokovic, Beyoncé, Scarlett Johansson</p></td>
</tr>
<tr class="row-even"><td><p>LOCATION</p></td>
<td><p>Mount Everest, River Nile, Machu Picchu Archaeological Park</p></td>
</tr>
<tr class="row-odd"><td><p>DATE</p></td>
<td><p>3rd April 1988, 7 June</p></td>
</tr>
<tr class="row-even"><td><p>TIME</p></td>
<td><p>8:45 A.M., one-thirty am</p></td>
</tr>
<tr class="row-odd"><td><p>GPE</p></td>
<td><p>France, Liechtenstein, Democratic Republic of Congo</p></td>
</tr>
<tr class="row-even"><td><p>MONEY</p></td>
<td><p>7 million dollars, 73.01 INR</p></td>
</tr>
</tbody>
</table>
<p>What should be considered as a named entity (NE) in a text is quite open for discussion and depends on the kind of information one wants to extract. However, the set of named entity classes that is widely used contains the three fundamental entity types, person (PER), location (LOC), and organization (ORG), collectively referred to as the
enamex since the MUC-6 competition (<a class="reference external" href="https://aclanthology.org/C96-1079.pdf">Grishman et al 1996</a>).</p>
</div>
<div class="section" id="b-why-are-named-entities-important-case-studies">
<h2>(b) Why are named entities important? (case studies)<a class="headerlink" href="#b-why-are-named-entities-important-case-studies" title="Permalink to this headline">¶</a></h2>
<p>The detection of entities can be considered as a first step in the exploration of data collections.</p>
<div class="section" id="classifying-content-for-news-providers">
<h3>Classifying content for news providers<a class="headerlink" href="#classifying-content-for-news-providers" title="Permalink to this headline">¶</a></h3>
<p>News publishers generate large amounts of content on a daily basis and managing them correctly is very important to get the most use of each article. NER can automatically scan an entire collection of articles and reveal which are the major people, organizations, and places discussed in them. Knowing these relevant information may help in automatically categorizing the articles in defined hierarchies and enable smooth content discovery. This could also save a lot of time and boost the efficiency of teams.</p>
</div>
<div class="section" id="automating-customer-support">
<h3>Automating customer support<a class="headerlink" href="#automating-customer-support" title="Permalink to this headline">¶</a></h3>
<p>There are a number of ways to make the process of customer feedback handling smooth and NER could be one of them. For example, the customer support department of an electronic store should handle multiple branches worldwide, thus it needs to go through a number mentions in the customer feedback comments. NER could provide entities as locations and products, and these can be then used to categorize the complaint and assign it to the relevant department within the organization that should be handling this.</p>
</div>
<div class="section" id="exploring-historical-documents">
<h3>Exploring historical documents<a class="headerlink" href="#exploring-historical-documents" title="Permalink to this headline">¶</a></h3>
<p>Historical newspapers are considered more and more as an important source of historical knowledge. As the amount of digitized data accumulates, tools for harvesting the data are needed to gather information. Tools like NER can be extremely valuable to researchers, historians, or librarians for adding structure to the volumes of unstructured data and for improving access to the historical digitized collections.  For example, a simple keyword search can already provide a historian with a sense of whether a collection contains material relevant for their research, thus saving many hours of visiting archives and skimming through pages. NER task can be used to detect person names and locations, these entities having an equally significant presence in the news domain, in which people are often at the core of the events reported in articles. For exampl, the EU’s digital platform for cultural heritage, <a class="reference external" href="http://www.europeana-newspapers.eu/named-entity-recognition-for-digitised-newspapers/">Europeana</a>, is using NER to make historical newspapers searchable.</p>
</div>
<div class="section" id="extracting-valuable-information-from-medical-documents">
<h3>Extracting valuable information from medical documents<a class="headerlink" href="#extracting-valuable-information-from-medical-documents" title="Permalink to this headline">¶</a></h3>
<p>Electronic health records are a valuable source of routinely collected health data that can be used for secondary purposes, including clinical and epidemiological research. They typically contain information on consultations, admissions, symptoms, clinical examinations, test results, diagnoses, treatments, and outcomes. NER can clinic letters or discharge summaries can ease the process of information extraction from free-text sources of prescription information, such as clinic letters or discharge summaries. In this case, the NER task can involve extracting different types of entities: drug, strength, duration, route, form, dosage, frequency, reason of administration, etc. NER can also recognize and match demographic factors that could provide analysts/doctors deeper insights.</p>
<p>Similar to MUC, another known competition initiated in 2004 by the Informatics for Integrating Biology and the Bedside (<a class="reference external" href="https://www.i2b2.org/">i2b2</a>) was designed to encourage the development of NLP techniques for the extraction of medication-related information from narrative patient records, in order to accelerate the translation of clinical findings into novel diagnostics and prognostics.</p>
</div>
<div class="section" id="aiding-risk-assessment-for-financial-institutions">
<h3>Aiding risk assessment for financial institutions<a class="headerlink" href="#aiding-risk-assessment-for-financial-institutions" title="Permalink to this headline">¶</a></h3>
<p>Risk assessment is a crucial activity for financial institutions because it helps them to determine the amount of capital they should hold to assure their stability. Manual extraction of relevant information from text-based financial documents is expensive and time-consuming. NER can extract credit risk attributes from a large volume of <em>live</em> financial documents, numbering in the millions of documents for a large bank financial documents. In the financial domain, example named entity types are: lenger, borrower, amount, date, etc.</p>
</div>
<div class="section" id="easing-the-research-process">
<h3>Easing the research process<a class="headerlink" href="#easing-the-research-process" title="Permalink to this headline">¶</a></h3>
<p>An online journal or conference publication site could hold millions of research papers and scholarly articles. There can be hundreds of papers on a single topic with slight modifications. Organizing all this data in a well-structured manner can be complex. Segregating the papers on the basis of the relevant entities it holds can save the trouble of going through the plethora of information on the subject matter. For instance, if the articles have in their metadata different types of entities (for example, NER can detect fields of study as <em>Named Entity Recognition</em> and <em>Information Extraction</em>), one can quickly find the articles where the use of <em>named entity recognition in historical documents</em> is discussed. This, NER could enable students and researchers to find relevant material faster by summarizing papers and archive material and highlighting key terms, topics, and themes.</p>
</div>
</div>
<div class="section" id="c-named-entity-recognition-with-nltk-spacy">
<h2>(c) Named Entity Recognition with NLTK &amp; spaCy<a class="headerlink" href="#c-named-entity-recognition-with-nltk-spacy" title="Permalink to this headline">¶</a></h2>
<p>Now, we explore the task of Named Entity Recognition (NER) <em>tagging</em> of sentences. <em>Tagging</em> (or <em>labelling</em>) means the detection of entities in text and the correct assignment of an entity type of them. In NLP, an <em>entity</em> is a sequence of one or more words (<em>tokens</em>). Thus, the task is to tag each token in a given sentence with an appropriate tag such as Person, Location, etc.</p>
<p>For detecting entities with NLP programming techniques, we continue with the usage of two libraries: NLTK and spaCy. <a class="reference external" href="https://www.nltk.org/">NLTK</a> is a widely used standard Natural Language Processing (NLP) and Computational Linguistics (CL) Python library with prebuilt functions and utilities for the ease of use and implementation. <a class="reference external" href="https://spacy.io/">spaCy</a> is an open-source software Python library for advanced natural language processing that covers multiple NLP tasks (part-of-speech tagging, named entity recognition, etc).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phrase1</span> <span class="o">=</span> <span class="s2">&quot;In 1979, after more than a century of vaccination campaigns around the planet, the World Health Organization certified that smallpox had been eradicated&quot;</span>
    
<span class="n">phrase2</span> <span class="o">=</span> <span class="s2">&quot;Beginning in February 1965, there were 8 weeks of unbroken bombing by U.S. forces of targets in North Vietnam. Over the next three years, the Unites States dropped more bombs than were dropped over Asia and Europe during World War II.&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phrase1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;In 1979, after more than a century of vaccination campaigns around the planet, the World Health Organization certified that smallpox had been eradicated&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phrase2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Beginning in February 1965, there were 8 weeks of unbroken bombing by U.S. forces of targets in North Vietnam. Over the next three years, the Unites States dropped more bombs than were dropped over Asia and Europe during World War II.&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="i-ner-with-nltk">
<h2>i. NER with <a class="reference external" href="https://www.nltk.org/">NLTK</a><a class="headerlink" href="#i-ner-with-nltk" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">sent_tokenize</span><span class="p">,</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">pos_tag</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">ne_chunk</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">phrase1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sentence:&quot;</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="n">pos_tags_sentence</span> <span class="o">=</span> <span class="n">pos_tag</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">ne_chunks_sentence</span> <span class="o">=</span> <span class="n">ne_chunk</span><span class="p">(</span><span class="n">pos_tags_sentence</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ne_chunks_sentence</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">LookupError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_1777</span><span class="o">/</span><span class="mf">699824466.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">ne_chunk</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="n">sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">phrase1</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> 
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nltk/tokenize/__init__.py</span> in <span class="ni">sent_tokenize</span><span class="nt">(text, language)</span>
<span class="g g-Whitespace">    </span><span class="mi">103</span>     <span class="p">:</span><span class="n">param</span> <span class="n">language</span><span class="p">:</span> <span class="n">the</span> <span class="n">model</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Punkt</span> <span class="n">corpus</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">105</span><span class="s2">     tokenizer = load(&#39;tokenizers/punkt/</span><span class="si">{0}</span><span class="s2">.pickle&#39;.format(language))</span>
<span class="g g-Whitespace">    </span><span class="mi">106</span><span class="s2">     return tokenizer.tokenize(text)</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nltk/data.py</span> in <span class="ni">load</span><span class="nt">(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)</span>
<span class="g g-Whitespace">    </span><span class="mi">866</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">867</span><span class="s2">     # Load the resource.</span>
<span class="ne">--&gt; </span><span class="mi">868</span><span class="s2">     opened_resource = _open(resource_url)</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">870</span><span class="s2">     if format == &#39;raw&#39;:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nltk/data.py</span> in <span class="ni">_open</span><span class="nt">(resource_url)</span>
<span class="g g-Whitespace">    </span><span class="mi">991</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">992</span><span class="s2">     if protocol is None or protocol.lower() == &#39;nltk&#39;:</span>
<span class="ne">--&gt; </span><span class="mi">993</span><span class="s2">         return find(path_, path + [&#39;&#39;]).open()</span>
<span class="g g-Whitespace">    </span><span class="mi">994</span><span class="s2">     elif protocol.lower() == &#39;file&#39;:</span>
<span class="g g-Whitespace">    </span><span class="mi">995</span><span class="s2">         # urllib might not use mode=&#39;rb&#39;, so handle this one ourselves:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/nltk/data.py</span> in <span class="ni">find</span><span class="nt">(resource_name, paths)</span>
<span class="g g-Whitespace">    </span><span class="mi">699</span><span class="s2">     sep = &#39;*&#39; * 70</span>
<span class="g g-Whitespace">    </span><span class="mi">700</span><span class="s2">     resource_not_found = &#39;</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&#39; % (sep, msg, sep)</span>
<span class="ne">--&gt; </span><span class="mi">701</span><span class="s2">     raise LookupError(resource_not_found)</span>
<span class="g g-Whitespace">    </span><span class="mi">702</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">703</span><span class="s2"> </span>

<span class="ne">LookupError</span>: 
<span class="s2">**********************************************************************</span>
<span class="s2">  Resource punkt not found.</span>
<span class="s2">  Please use the NLTK Downloader to obtain the resource:</span>

<span class="s2">  &gt;&gt;&gt; import nltk</span>
<span class="s2">  &gt;&gt;&gt; nltk.download(&#39;punkt&#39;)</span>
<span class="s2">  </span>
<span class="s2">  For more information see: https://www.nltk.org/data.html</span>

<span class="s2">  Attempted to load tokenizers/punkt/PY3/english.pickle</span>

<span class="s2">  Searched in:</span>
<span class="s2">    - &#39;/home/runner/nltk_data&#39;</span>
<span class="s2">    - &#39;/opt/hostedtoolcache/Python/3.8.11/x64/nltk_data&#39;</span>
<span class="s2">    - &#39;/opt/hostedtoolcache/Python/3.8.11/x64/share/nltk_data&#39;</span>
<span class="s2">    - &#39;/opt/hostedtoolcache/Python/3.8.11/x64/lib/nltk_data&#39;</span>
<span class="s2">    - &#39;/usr/share/nltk_data&#39;</span>
<span class="s2">    - &#39;/usr/local/share/nltk_data&#39;</span>
<span class="s2">    - &#39;/usr/lib/nltk_data&#39;</span>
<span class="s2">    - &#39;/usr/local/lib/nltk_data&#39;</span>
<span class="s2">    - &#39;&#39;</span>
<span class="s2">**********************************************************************</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">phrase2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sentence:&quot;</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="n">pos_tags_sentence</span> <span class="o">=</span> <span class="n">pos_tag</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">ne_chunks_sentence</span> <span class="o">=</span> <span class="n">ne_chunk</span><span class="p">(</span><span class="n">pos_tags_sentence</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ne_chunks_sentence</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sentence: Beginning in February 1965, there were 8 weeks of unbroken bombing by U.S. forces of targets in North Vietnam.
(S
  Beginning/VBG
  in/IN
  February/NNP
  1965/CD
  ,/,
  there/EX
  were/VBD
  8/CD
  weeks/NNS
  of/IN
  unbroken/JJ
  bombing/NN
  by/IN
  (GPE U.S./NNP)
  forces/NNS
  of/IN
  targets/NNS
  in/IN
  (GPE North/NNP Vietnam/NNP)
  ./.)
Sentence: Over the next three years, the Unites States dropped more bombs than were dropped over Asia and Europe during World War II.
(S
  Over/IN
  the/DT
  next/JJ
  three/CD
  years/NNS
  ,/,
  the/DT
  (GPE Unites/NNP States/NNPS)
  dropped/VBD
  more/JJR
  bombs/NNS
  than/IN
  were/VBD
  dropped/VBN
  over/IN
  (GPE Asia/NNP)
  and/CC
  (GPE Europe/NNP)
  during/IN
  World/NNP
  War/NNP
  II/NNP
  ./.)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="ii-ner-with-spacy">
<h2>ii. NER with <a class="reference external" href="https://spacy.io/">spaCy</a><a class="headerlink" href="#ii-ner-with-spacy" title="Permalink to this headline">¶</a></h2>
<p>spaCy currently provides support for the following <a class="reference external" href="https://spacy.io/usage/models">languages</a>. For applying NER for an English text, we need to download a spaCy NER model for <a class="reference external" href="https://spacy.io/models/en">English</a>. We choose to download <code class="docutils literal notranslate"><span class="pre">en_core_web_sm</span></code> because it is the smallest one in regards to download size (12Mb).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python -m spacy download en_core_web_sm
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy</span> <span class="kn">import</span> <span class="n">displacy</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">phrase1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Entity:&#39;</span><span class="p">,</span> <span class="n">entity</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;---&#39;</span><span class="p">,</span> <span class="s1">&#39;Entity Type (tag/label):&#39;</span><span class="p">,</span> <span class="n">entity</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Entity: 1979 --- Entity Type (tag/label): DATE
Entity: more than a century --- Entity Type (tag/label): DATE
Entity: the World Health Organization --- Entity Type (tag/label): ORG
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">phrase2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Entity:&#39;</span><span class="p">,</span> <span class="n">entity</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;---&#39;</span><span class="p">,</span>  <span class="s1">&#39;Entity Type:&#39;</span><span class="p">,</span> <span class="n">entity</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Entity: February 1965 --- Entity Type: DATE
Entity: 8 weeks --- Entity Type: DATE
Entity: U.S. --- Entity Type: GPE
Entity: North Vietnam --- Entity Type: LOC
Entity: the next three years --- Entity Type: DATE
Entity: the Unites States --- Entity Type: GPE
Entity: Asia --- Entity Type: LOC
Entity: Europe --- Entity Type: LOC
Entity: World War II --- Entity Type: EVENT
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">sents</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sentence&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">sent</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sentence 0 : Beginning in February 1965, there were 8 weeks of unbroken bombing by U.S. forces of targets in North Vietnam.
Sentence 1 : Over the next three years, the Unites States dropped more bombs than were dropped over Asia and Europe during World War II.
</pre></div>
</div>
</div>
</div>
<p>The IOB format (short for <strong>i</strong>nside, <strong>o</strong>utside, <strong>b</strong>eginning) is a common tagging format for tagging tokens in a chunking task in computational linguistics (ex. named entity recognition) to describe the entity boundaries. In IOB, the I- prefix before a tag indicates that the tag is inside a chunk. An O tag indicates that a token belongs to no chunk. The B- prefix before a tag indicates that the tag is the beginning of a chunk that immediately follows another chunk without O tags between them.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Named Entity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>I</p></td>
<td><p>An inner token of a multi-token entity</p></td>
</tr>
<tr class="row-odd"><td><p>O</p></td>
<td><p>A non-entity token</p></td>
</tr>
<tr class="row-even"><td><p>B</p></td>
<td><p>The beginning token of a multi-token entity</p></td>
</tr>
</tbody>
</table>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>U.S.</p></th>
<th class="head"><p>dropped</p></th>
<th class="head"><p>more</p></th>
<th class="head"><p>bombs</p></th>
<th class="head"><p>than</p></th>
<th class="head"><p>over</p></th>
<th class="head"><p>Asia</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>Europe</p></th>
<th class="head"><p>during</p></th>
<th class="head"><p>World</p></th>
<th class="head"><p>War</p></th>
<th class="head"><p>II</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>I-GPE</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>I-LOC</p></td>
<td><p>O</p></td>
<td><p>I-LOC</p></td>
<td><p>O</p></td>
<td><p>I-EVENT</p></td>
<td><p>I-EVENT</p></td>
<td><p>I-EVENT</p></td>
</tr>
</tbody>
</table>
<p>Another similar format which is widely used is IOB2 format, which is the same as the IOB format except that the B- tag is used in the beginning of every chunk (i.e. all chunks start with the B- tag).</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>U.S.</p></th>
<th class="head"><p>dropped</p></th>
<th class="head"><p>more</p></th>
<th class="head"><p>bombs</p></th>
<th class="head"><p>than</p></th>
<th class="head"><p>over</p></th>
<th class="head"><p>Asia</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>Europe</p></th>
<th class="head"><p>during</p></th>
<th class="head"><p>World</p></th>
<th class="head"><p>War</p></th>
<th class="head"><p>II</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>B-GPE</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>B-LOC</p></td>
<td><p>O</p></td>
<td><p>B-LOC</p></td>
<td><p>O</p></td>
<td><p>B-EVENT</p></td>
<td><p>I-EVENT</p></td>
<td><p>I-EVENT</p></td>
</tr>
</tbody>
</table>
<p>Other tagging scheme is BIOES/BILOU, where ‘E’ and ‘L’ denotes Last or Ending token is such a sequence and ‘S’ denotes Single element or ‘U’ Unit element.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Named Entity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>B</p></td>
<td><p>The first token of a multi-token entity</p></td>
</tr>
<tr class="row-odd"><td><p>I</p></td>
<td><p>An inner token of a multi-token entity</p></td>
</tr>
<tr class="row-even"><td><p>L/E</p></td>
<td><p>The last/ending token of a multi-token entity</p></td>
</tr>
<tr class="row-odd"><td><p>O</p></td>
<td><p>A non-entity token</p></td>
</tr>
<tr class="row-even"><td><p>U/S</p></td>
<td><p>A single token entity</p></td>
</tr>
</tbody>
</table>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>U.S.</p></th>
<th class="head"><p>dropped</p></th>
<th class="head"><p>more</p></th>
<th class="head"><p>bombs</p></th>
<th class="head"><p>than</p></th>
<th class="head"><p>over</p></th>
<th class="head"><p>Asia</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>Europe</p></th>
<th class="head"><p>during</p></th>
<th class="head"><p>World</p></th>
<th class="head"><p>War</p></th>
<th class="head"><p>II</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>S-GPE</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p>S-LOC</p></td>
<td><p>O</p></td>
<td><p>S-LOC</p></td>
<td><p>O</p></td>
<td><p>B-EVENT</p></td>
<td><p>I-EVENT</p></td>
<td><p>E-EVENT</p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ie_preprocess</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">nltk</span><span class="o">.</span><span class="n">ne_chunk</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sentences</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="iii-how-to-build-or-train-a-ner-model">
<h2>iii. How to build or train a NER model<a class="headerlink" href="#iii-how-to-build-or-train-a-ner-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dataset">
<h3>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<p>The CoNLL 2003 dataset consists of English newswire from the Reuters RCV1 corpus and it includes standard train, development, and test sets. This corpus consists of Reuters news stories between August 1996 and August 1997. For the training and development set, ten days’ worth of data were taken from the files representing the end of August 1996. For the test set, the texts were from December 1996. The preprocessed raw data covers the month of September 1996.</p>
<p>The learning methods will be trained with the training data. The development data should be used for tuning the parameters of the learning methods. The test data will be used to measuring the performance of the methods.</p>
<p>The corpus is available with some linguistic preprocessing already done: for all data, a tokenizer, part-of-speech tagger, and a chunker were applied to the raw data. The data contains entities of four types: persons (PER),
organizations (ORG), locations (LOC) and miscellaneous names (MISC).</p>
</div>
<div class="section" id="data-format-iob-tagging-scheme">
<h3>Data format (IOB tagging scheme)<a class="headerlink" href="#data-format-iob-tagging-scheme" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>word</p></th>
<th class="head"><p>part-of-speech</p></th>
<th class="head"><p>chunk</p></th>
<th class="head"><p>entity type</p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>U.N.</p></td>
<td><p>NNP</p></td>
<td><p>I-NP</p></td>
<td><p>I-ORG</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>official</p></td>
<td><p>NN</p></td>
<td><p>I-NP</p></td>
<td><p>O</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Ekeus</p></td>
<td><p>NNP</p></td>
<td><p>I-NP</p></td>
<td><p>I-PER</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>heads</p></td>
<td><p>VBZ</p></td>
<td><p>I-VP</p></td>
<td><p>O</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>for</p></td>
<td><p>IN</p></td>
<td><p>I-PP</p></td>
<td><p>O</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Baghdad</p></td>
<td><p>NNP</p></td>
<td><p>I-NP</p></td>
<td><p>I-LOC</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>.</p></td>
<td><p>.</p></td>
<td><p>O</p></td>
<td><p>O</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">read_csv</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/2.2.2/data.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span> 
<span class="c1"># train_sents = list(nltk.corpus.conll2002.iob_sents(&#39;eng.train&#39;))??</span>

<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>pos</th>
      <th>chunk</th>
      <th>entity_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CRICKET</td>
      <td>NNP</td>
      <td>I-NP</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-</td>
      <td>:</td>
      <td>O</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LEICESTERSHIRE</td>
      <td>NNP</td>
      <td>I-NP</td>
      <td>I-ORG</td>
    </tr>
    <tr>
      <th>3</th>
      <td>TAKE</td>
      <td>NNP</td>
      <td>I-NP</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>OVER</td>
      <td>IN</td>
      <td>I-PP</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>pos</th>
      <th>chunk</th>
      <th>entity_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>50721</th>
      <td>.</td>
      <td>.</td>
      <td>O</td>
      <td>O</td>
    </tr>
    <tr>
      <th>50722</th>
      <td>--</td>
      <td>:</td>
      <td>O</td>
      <td>O</td>
    </tr>
    <tr>
      <th>50723</th>
      <td>Dhaka</td>
      <td>NNP</td>
      <td>I-NP</td>
      <td>I-ORG</td>
    </tr>
    <tr>
      <th>50724</th>
      <td>Newsroom</td>
      <td>NNP</td>
      <td>I-NP</td>
      <td>I-ORG</td>
    </tr>
    <tr>
      <th>50725</th>
      <td>880-2-506363</td>
      <td>CD</td>
      <td>I-NP</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="how-to-choose-the-train-dev-and-test-sets">
<h3>How to choose the train, dev and test sets<a class="headerlink" href="#how-to-choose-the-train-dev-and-test-sets" title="Permalink to this headline">¶</a></h3>
<p>To build a well-performing machine learning (ML) model, it is essential to train the model on and test it against data that come from the same target distribution.</p>
<ul class="simple">
<li><p><strong>Training dataset</strong>: The actual dataset that we use to train the model. The model sees and learns from this data.</p></li>
<li><p><strong>Validation dataset</strong>: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while training (<em>tuning model hyperparameters</em>). The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration. The validation set is used to evaluate a given model, but this is for frequent evaluation. The validation set is also known as the Dev set or the Development set. This makes sense since this dataset helps during the <em>development</em> stage of the model.</p></li>
<li><p><strong>Test dataset</strong>: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset. The Test dataset provides the gold standard used to evaluate the model. It is only used once a model is completely trained (using the train and validation sets). The test set is generally what is used to evaluate competing models. Many times the validation set is used as the test set, but it is not good practice. The test set is generally well curated. It contains carefully sampled data that spans the various classes that the model would face, when used in the real world.</p></li>
</ul>
<p>We will split our data using the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> method from the Scikit-learn library. The procedure has one main configuration parameter, which is the size of the train and test sets. This is most commonly expressed as a percentage between 0 and 1 for either the train or test datasets. For example, a training set with the size of 0.67 (67 percent) means that the remainder percentage 0.33 (33 percent) is assigned to the test set.</p>
<p>There is no optimal split percentage. Common split percentages include:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-Train: 80%, Dev: 10%, Test: 10%
-Train: 33%, Dev: 33%, Test: 33%
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_dev</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_dev</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;entity_type&#39;</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
<span class="n">X_dev</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_dev</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_dev</span><span class="p">,</span> <span class="n">y_dev</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.50</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_dev</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40575 5072 5072
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">DictVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>

<span class="n">X_train_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_dev_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_dev</span><span class="p">)</span>
<span class="n">X_test_features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">multinomial_naive_bayes</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">multinomial_naive_bayes</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_features</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MultinomialNB(alpha=0.01)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>The performance in this task is measured with <strong>Precision</strong> (P), <strong>Recall</strong> (R), and <strong>F1</strong> (F-measure). <strong>Precision</strong> is the percentage of named entities found by the learning system that are correct. <strong>Recall</strong> is the percentage of named entities present in the corpus that are found by the system. A named entity is correct only if it is an exact match of the corresponding entity in the data file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">y_dev_predictions</span> <span class="o">=</span> <span class="n">multinomial_naive_bayes</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_dev_features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_dev_predictions</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_dev</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

      B-MISC     1.0000    0.0000    0.0000         1
       I-LOC     0.8832    0.7632    0.8188       228
      I-MISC     0.9041    0.5789    0.7059       114
       I-ORG     0.8605    0.5468    0.6687       203
       I-PER     0.9777    0.5418    0.6972       323
           O     0.9317    0.9962    0.9629      4203

    accuracy                         0.9292      5072
   macro avg     0.9262    0.5711    0.6422      5072
weighted avg     0.9290    0.9292    0.9217      5072
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_dev_predictions</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_dev</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

      B-MISC     1.0000    0.0000    0.0000         1
      I-MISC     0.9041    0.5789    0.7059       114
       B-LOC     1.0000    1.0000    1.0000         0
       I-LOC     0.8832    0.7632    0.8188       228
       B-ORG     1.0000    1.0000    1.0000         0
       I-ORG     0.8605    0.5468    0.6687       203
       B-PER     1.0000    1.0000    1.0000         0
       I-PER     0.9777    0.5418    0.6972       323

   micro avg     0.9100    0.6053    0.7270       869
   macro avg     0.9532    0.6788    0.7363       869
weighted avg     0.9159    0.6053    0.7228       869
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">logistic_regression</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">logistic_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_features</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(max_iter=500)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_dev_predictions</span> <span class="o">=</span> <span class="n">logistic_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_dev_features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_dev_predictions</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_dev</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

      B-MISC     1.0000    0.0000    0.0000         1
      I-MISC     0.9592    0.4123    0.5767       114
       B-LOC     1.0000    1.0000    1.0000         0
       I-LOC     0.9161    0.6228    0.7415       228
       B-ORG     1.0000    1.0000    1.0000         0
       I-ORG     0.8036    0.2217    0.3475       203
       B-PER     1.0000    1.0000    1.0000         0
       I-PER     0.9646    0.3375    0.5000       323

   micro avg     0.9196    0.3947    0.5523       869
   macro avg     0.9554    0.5743    0.6457       869
weighted avg     0.9136    0.3947    0.5372       869
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="n">neural_network</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">()</span>
<span class="n">neural_network</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_features</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MLPClassifier()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_dev_predictions</span> <span class="o">=</span> <span class="n">neural_network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_dev_features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_dev_predictions</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_dev</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

      B-MISC     1.0000    0.0000    0.0000         1
      I-MISC     0.8554    0.6228    0.7208       114
       B-LOC     1.0000    1.0000    1.0000         0
       I-LOC     0.8483    0.7851    0.8155       228
       B-ORG     1.0000    1.0000    1.0000         0
       I-ORG     0.8740    0.5468    0.6727       203
       B-PER     1.0000    1.0000    1.0000         0
       I-PER     0.9777    0.5418    0.6972       323

   micro avg     0.8933    0.6168    0.7297       869
   macro avg     0.9444    0.6871    0.7383       869
weighted avg     0.9035    0.6168    0.7248       869
</pre></div>
</div>
</div>
</div>
<p>The best results on dev ..</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test_predictions</span> <span class="o">=</span> <span class="n">neural_network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_features</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_test_predictions</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

      B-MISC     1.0000    1.0000    1.0000         0
      I-MISC     0.8454    0.6457    0.7321       127
       B-LOC     1.0000    1.0000    1.0000         0
       I-LOC     0.7990    0.7756    0.7871       205
       B-ORG     1.0000    1.0000    1.0000         0
       I-ORG     0.8231    0.5194    0.6369       206
       B-PER     1.0000    1.0000    1.0000         0
       I-PER     0.9840    0.5987    0.7445       309

   micro avg     0.8681    0.6293    0.7296       847
   macro avg     0.9314    0.8174    0.8626       847
weighted avg     0.8793    0.6293    0.7268       847
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="general-principles-ml-training-data-etc">
<h2>General principles (ML, training data, etc)<a class="headerlink" href="#general-principles-ml-training-data-etc" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="d-state-of-the-art-examples-list-of-sota-papers">
<h2>(d) State-of-the-art examples (list of SotA papers)<a class="headerlink" href="#d-state-of-the-art-examples-list-of-sota-papers" title="Permalink to this headline">¶</a></h2>
<p>The first end-to-end systems for sequence labeling tasks are based on pre-trained word and character embeddings encoded either by a bidirectional Long Short Term Memory (BiLSTM) network or a Convolutional Neural Network (CNN) (<a class="reference external" href="https://arxiv.org/abs/1603.01360">Lample et al., 2016</a> and <a class="reference external" href="https://arxiv.org/abs/1603.01354">Ma and Hovy 2016</a>), along with a Conditional Random Fields (CRF) decoder. One shortcoming of this type of model is that they were based on a single context-independent representation for each word. This problem has been further attenuated by methods based on language model pre-training that produced context-dependent word representations.
These recent large-scale language models methods such as ELMo (<a class="reference external" href="https://arxiv.org/abs/1705.00108">Peters et al. 2017</a>) and BERT (<a class="reference external" href="https://arxiv.org/abs/1810.04805">Devlin et al., 2018</a>) further enhanced the performance of NER, yielding <a class="reference external" href="http://nlpprogress.com/english/named_entity_recognition.html">state-of-the-art performances</a>.</p>
<ul class="simple">
<li><p>bidirectional Long Short Term Memory (BiLSTM) network <a class="reference external" href="https://arxiv.org/abs/1603.01360">Lample et al., 2016</a></p></li>
<li><p>Convolutional Neural Network (CNN) <a class="reference external" href="https://arxiv.org/abs/1603.01354">Ma and Hovy 2016</a>)</p></li>
<li><p>..</p></li>
</ul>
</div>
<div class="section" id="e-entity-linking">
<h2>(e) Entity linking<a class="headerlink" href="#e-entity-linking" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="d-use-case-mapping-locations-on-a-map">
<h2>(d) Use-case (mapping locations on a map)<a class="headerlink" href="#d-use-case-mapping-locations-on-a-map" title="Permalink to this headline">¶</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./unit2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By DiMPAH IO4 Team<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>